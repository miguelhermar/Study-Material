{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f587f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c819f59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/18 10:25:10 WARN Utils: Your hostname, miguels-MBP.local resolves to a loopback address: 127.0.0.1; using 192.168.100.17 instead (on interface en0)\n",
      "24/03/18 10:25:10 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/18 10:25:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"FirstApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49cb38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.100.17:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FirstApp</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=FirstApp>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/18 10:25:22 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c87a550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       1| 2017-07-01 00:06:25|  2017-07-01 00:10:50|              1|          1.2|         1|                 N|         249|          90|           1|        5.5|  0.5|    0.5|      1.35|         0.0|                  0.3|        8.15|\n",
      "|       1| 2017-07-01 00:20:04|  2017-07-01 00:21:38|              2|          0.2|         1|                 N|         249|         158|           2|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|\n",
      "|       1| 2017-07-01 00:44:10|  2017-07-01 00:59:29|              1|          4.3|         1|                 N|         100|          45|           1|       15.5|  0.5|    0.5|      3.35|         0.0|                  0.3|       20.15|\n",
      "|       1| 2017-07-01 00:07:33|  2017-07-01 00:31:30|              1|          8.3|         1|                 N|         138|         162|           1|       27.0|  0.5|    0.5|       6.8|        5.76|                  0.3|       40.86|\n",
      "|       1| 2017-07-01 00:01:17|  2017-07-01 00:16:18|              1|          1.9|         1|                 N|         107|         158|           1|       10.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        11.8|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\",True).option(\"inferSchema\",True).load(\"./trip_yellow_taxi.csv\")\n",
    "# df.write.format(\"csv\").option(\"header\",True).save(\"example.csv\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "190f3e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e172a13",
   "metadata": {},
   "source": [
    "1. Fetch the record having VendorID as '2' AND tpep_pickup_datetime as '2017-10-01 00:15:30' AND tpep_dropoff_datetime as '2017-10-01 00:25:11' AND passenger_count as '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11807a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.VendorID=='2').filter(df.tpep_pickup_datetime=='2017-10-01 00:15:30')\\\n",
    "                           .filter(df.tpep_dropoff_datetime=='2017-10-01 00:25:11')\\\n",
    "                           .filter(df.passenger_count=='1')\\\n",
    "                           .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6eec2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('taxi_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45c84ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_QUERY = \"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        taxi_data\n",
    "    WHERE VendorID==2\n",
    "        AND tpep_pickup_datetime=='2017-10-01 00:15:30'\n",
    "        AND tpep_dropoff_datetime=='2017-10-01 00:25:11'\n",
    "        AND passenger_count=='1'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cca8e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "|       2| 2017-10-01 00:15:30|  2017-10-01 00:25:11|              1|         2.17|         1|                 N|         141|         142|           1|        9.0|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(FILTER_QUERY).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacd4e6d",
   "metadata": {},
   "source": [
    " 2. Filter all the records having RatecodeID as 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095053f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "|       1| 2017-12-01 00:42:45|  2017-12-01 01:04:59|              1|         23.3|         4|                 N|         265|          82|           3|      115.5|  0.5|    0.5|       0.0|         0.0|                  0.3|       116.8|\n",
      "|       1| 2017-12-01 02:49:44|  2017-12-01 02:51:13|              1|          0.0|         4|                 N|         265|         265|           3|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.8|\n",
      "|       1| 2017-12-01 02:52:20|  2017-12-01 02:54:50|              1|          0.7|         4|                 N|         265|         265|           3|        6.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.3|\n",
      "|       2| 2017-12-01 00:37:31|  2017-12-01 01:17:51|              1|        21.12|         4|                 N|         209|         265|           1|       64.5|  0.5|    0.5|     13.16|         0.0|                  0.3|       78.96|\n",
      "|       2| 2017-12-01 00:11:57|  2017-12-01 00:57:45|              1|        16.54|         4|                 N|          48|         265|           1|       54.5|  0.5|    0.5|     16.74|         0.0|                  0.3|       72.54|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.RatecodeID=='4').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d23d7b",
   "metadata": {},
   "source": [
    " 3. Group By all the records based on payment type and find the count for each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d3b8afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|payment_type|count|\n",
      "+------------+-----+\n",
      "|           1|14322|\n",
      "|           3| 2484|\n",
      "|           4|  396|\n",
      "|           2| 7452|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"payment_type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0936ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32133c30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22ac53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26db6697",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTER_QUERY = \"\"\"\n",
    "    SELECT\n",
    "        extract(year from tpep_pickup_datetime), count(1)\n",
    "    FROM\n",
    "        taxi_data\n",
    "    GROUP BY extract(year from tpep_pickup_datetime)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2c2f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------+\n",
      "|extract(year FROM tpep_pickup_datetime)|count(1)|\n",
      "+---------------------------------------+--------+\n",
      "|                                   2017|   24654|\n",
      "+---------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(FILTER_QUERY).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d32adda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbbf8f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new partition key\n",
    "# add a new column to the DataFrame or replace an existing one if the name matches. \n",
    "# The new column is named p_date.\n",
    "# to_date converts the tpep_pickup_datetime timestamp into a date, \n",
    "# removing any time information, and stores this in the new p_date column\n",
    "df_sink = df.withColumn('p_date', to_date(col('tpep_pickup_datetime')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e3a79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|    p_date|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+----------+\n",
      "|       1| 2017-07-01 00:06:25|  2017-07-01 00:10:50|              1|          1.2|         1|                 N|         249|          90|           1|        5.5|  0.5|    0.5|      1.35|         0.0|                  0.3|        8.15|2017-07-01|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sink.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3a0f635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Write to local storage, if not done already\n",
    "# Writes the DataFrame in the Parquet file format, which is a columnar storage format offering efficient data compression and encoding schemes. \n",
    "df_sink.write.partitionBy(\"p_date\").mode(\"overwrite\").parquet(\"datasets/yellow_taxis_daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd06a3",
   "metadata": {},
   "source": [
    "### Let's create a real \"dimension\" table, for our RateCodeID\n",
    "1. Standard rate\n",
    "2. JFK\n",
    "3. Newark\n",
    "4. Nassau or Westchester \n",
    "5. Negotiated fare\n",
    "6. Group ride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae2980da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, StructField, StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e474a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Rate Code IDs\n",
    "data = [(\"1\", \"Standard rate\"), (\"2\", \"JFK\"), (\"3\", \"Newark\"),(\"4\",\"Nassau or Westchester \"),(\"5\",\"Negotiated fare\"), (\"6\",\"Group ride\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7fe62321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema, to ensure data types\n",
    "schema = StructType([ \\\n",
    "    StructField(\"rate_code_id\",StringType(),True), \\\n",
    "    StructField(\"RatecodeName\",StringType(),True)\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9d8ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe for Rate Codes\n",
    "df_rate_codes = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8f5a9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|rate_code_id|        RatecodeName|\n",
      "+------------+--------------------+\n",
      "|           1|       Standard rate|\n",
      "|           2|                 JFK|\n",
      "|           3|              Newark|\n",
      "|           4|Nassau or Westche...|\n",
      "|           5|     Negotiated fare|\n",
      "|           6|          Group ride|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show rates\n",
    "df_rate_codes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2616fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+-------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|rate_code_id| RatecodeName|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+-------------+\n",
      "|       1| 2017-12-01 03:49:15|  2017-12-01 04:26:21|              2|          8.4|         1|                 N|         164|          37|           4|       31.5|  0.5|    0.5|       0.0|        5.76|                  0.3|       38.56|           1|Standard rate|\n",
      "|       1| 2017-12-01 03:22:41|  2017-12-01 03:23:51|              1|          0.3|         1|                 N|         100|          48|           4|        3.0|  0.5|    0.5|       0.0|         0.0|                  0.3|         4.3|           1|Standard rate|\n",
      "|       1| 2017-12-01 03:16:49|  2017-12-01 03:27:18|              1|          3.4|         1|                 N|         224|         140|           4|       12.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        13.8|           1|Standard rate|\n",
      "|       1| 2017-12-01 03:22:28|  2017-12-01 03:28:27|              1|          1.0|         1|                 N|         246|         234|           4|        6.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.8|           1|Standard rate|\n",
      "|       1| 2017-12-01 03:38:32|  2017-12-01 03:45:42|              1|          2.1|         1|                 N|         231|         186|           4|        8.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         9.8|           1|Standard rate|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inner join example:\n",
    "df.join(df_rate_codes, df[\"RatecodeID\"] == df_rate_codes[\"rate_code_id\"], \"inner\").show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "914b5360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|RatecodeID|count(1)|\n",
      "+----------+--------+\n",
      "|         1|    3450|\n",
      "|         3|      30|\n",
      "|         5|      72|\n",
      "|         4|   21018|\n",
      "|         2|      84|\n",
      "+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL Statement\n",
    "spark.sql('''\n",
    "          select RatecodeID, count(1)\n",
    "          from taxi_data\n",
    "          group by RatecodeID\n",
    "          ''').show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78b8c06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|rate_code_id|RatecodeName|\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.join(df_rate_codes, df[\"RatecodeID\"] == df_rate_codes[\"rate_code_id\"], \"left\").where(\"RatecodeID is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b0d8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
